{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP+CSS 201 Tutorial - Beyond BOW: Text Analysis with Contextualized Topic Models",
      "provenance": [],
      "collapsed_sections": [
        "YSxaxusuf_rg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blazers/Introduction-to-deep-learning-code-examples/blob/master/NLP%2BCSS_201_Tutorial_Beyond_BOW_Text_Analysis_with_Contextualized_Topic_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmZ1uZecv7qW"
      },
      "source": [
        "# Tutorial \"Beyond the BOW: Text Analysis with Contextualized Topic Models\"\n",
        "\n",
        "### NLP+CSS 201 Series, November 22, 2021\n",
        "\n",
        "This tutorial will introduce Contextualized Topic Models (CTM), neural topic models which combine **contextualized document embeddings** with the classical BoW representations to increase the quality of the topics. Moreover, we will see how we can use multilingual embeddings to allow the model to **learn topics in one language and predict them for documents in unseen languages**, addressing a task of zero-shot cross-lingual topic modeling.\n",
        "\n",
        "Contact: \n",
        "\n",
        "*   Silvia Terragni \n",
        "*   s.terragni4@campus.unimib.it\n",
        "*   [silviatti.github.io](silviatti.github.io)\n",
        "\n",
        "Main References:\n",
        "\n",
        "* GitHub repo: https://github.com/MilaNLProc/contextualized-topic-models\n",
        "* [Blog post on cross-lingual topic modeling](https://fede-bianchi.medium.com/contextualized-topic-modeling-with-python-eacl2021-eacf6dfa576)\n",
        "* [Paper \"Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence\"](https://aclanthology.org/2021.acl-short.96/)\n",
        "* [Paper \"Cross-lingual Contextualized Topic Models with Zero-shot Learning\"](https://aclanthology.org/2021.eacl-main.143.pdf)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSAzV6v4DHQI"
      },
      "source": [
        "## Quick intro: What is Topic Modeling?\n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/topic_modeling.PNG)\n",
        "\n",
        "\n",
        "A topic model is usually an unsupervised model that aims at discovering the underlying themes or *topics* in large collections of documents.  \n",
        "\n",
        "**Main inputs:**\n",
        "\n",
        "*   Corpus of documents (D)\n",
        "*   Number of topics (K)\n",
        "\n",
        "**Main outputs:**\n",
        "\n",
        "*   Topics or topic indicators (lists of words or distributions of the words in the vocabulary)  \n",
        "*   Distributions of the topics on the documents\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCIg_sic6Wdk"
      },
      "source": [
        "## Topic Models as Probabilistic Models\n",
        "\n",
        "### Document representation\n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/doc_simplex.PNG)\n",
        "\n",
        "We can express a document as a **multinomial distribution over the topics**: a document talks about different topics in different proportions\n",
        "\n",
        "### Topic representation\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/topic_distrib.PNG)\n",
        "\n",
        "We can express it as a **multinomial distribution over the vocabulary**: a topic is not just a unordered list of words, but each word has a specific probability weight. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSfI4m0vC6WO"
      },
      "source": [
        "## What is a Neural Topic model? \n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/neural_topic_modeling.PNG)\n",
        "\n",
        "\n",
        "It is usually based on the Variational Autoencoder architecture: \n",
        "*   The encoder network learns the parameters of a probability distribution and from this distribution we sample the K-dimensional topical document representation (or distribution)\n",
        "*   The decoder network aims to reconstruct the original BoW document representation\n",
        "*   We get the top words of the documents from the weight matrix that reconstructs the BoW representations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRRbCYfpFS19"
      },
      "source": [
        "### BoW Limitation: \n",
        "The BoW representation **disregards the syntactic and semantic** information of the words in a document\n",
        "\n",
        "For example: \n",
        "\"*the department chair couches offers*\" and \"*the chair department offers couches*\" have the same BoW but **if we knew the context** of the word \"chair\" it would be easier to assign it the correct topic.\n",
        "\n",
        "Note: also LDA has the same limitation! It assumes the words in a document are independently and identically distributed (i.i.d. assumption)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02WFqdBRF9pZ"
      },
      "source": [
        "## Contextualized Representations\n",
        "\n",
        "Current language models (e.g. BERT) are trained on huge document collections and can capture syntactic and semantic information of the words and documents. \n",
        "\n",
        "They can learn **contextualized representations of words**, i.e. word embeddings that change depending on the context of the given word \n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/contextualized_embeddings.png)\n",
        "\n",
        "Image source: http://ai.stanford.edu/blog/contextual/\n",
        "\n",
        "\n",
        "### Contextualized representations of documents (SentenceBERT)\n",
        "\n",
        "We can also learn contextualized representations of the documents by **averaging over the word representations of the words** of a document \n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/sentencebert.PNG)\n",
        "\n",
        "*NOTE*: These representations can also be multilingual! \n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/multilingual_contextualized_embeddings.png)\n",
        "\n",
        "\n",
        "Can we use this type of representations to improve topic models and overcome the BoW limitation? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv0XIKH4KAzR"
      },
      "source": [
        "## Contextualized Topic Models: the Combined Topic Model\n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/combined_ctm.PNG)\n",
        "\n",
        "We can concatenate the two representations (BoW and contextualized) to help the model learn better topical representations of the documents \n",
        "\n",
        "\n",
        "Let see how this works in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln23-soXeQk3"
      },
      "source": [
        "## Enabling the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "[Reference](https://colab.research.google.com/notebooks/gpu.ipynb)\n",
        "\n",
        "\n",
        "## Contextualized Topic Models (python library)\n",
        "\n",
        "![](https://raw.githubusercontent.com/MilaNLProc/contextualized-topic-models/master/img/logo.png)\n",
        "\n",
        "You can find the CTM package [here](https://github.com/MilaNLProc/contextualized-topic-models).\n",
        "\n",
        "![https://pypi.python.org/pypi/contextualized_topic_models](https://img.shields.io/pypi/v/contextualized_topic_models.svg) ![https://pepy.tech/badge/contextualized-topic-models](https://pepy.tech/badge/contextualized-topic-models)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsNRo8I8Yem2"
      },
      "source": [
        "# Installing Contextualized Topic Models\n",
        "\n",
        "First, we install the contextualized topic model library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUw5EQi8v9r1"
      },
      "source": [
        "%%capture\n",
        "!pip install contextualized_topic_models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgxRbgSZ9MsB"
      },
      "source": [
        "# Data\n",
        "\n",
        "We are going to use the x-stance dataset [[paper](http://ceur-ws.org/Vol-2624/paper9.pdf) and [original data](https://github.com/ZurichNLP/xstance)]. \n",
        "\n",
        "\n",
        "* X-stance comprises more than 150 questions about Swiss politics and more than 67k answers given by candidates running for political office in Switzerland. \n",
        "* Questions are available in four languages: English, Swiss Standard German, French, and Italian. We only have answers in German, French and Italian. \n",
        "* The language of a comment depends on the candidateâ€™s region of origin. The data cover 175 communal, cantonal and national elections between 2011 and 2020. \n",
        "* The questions asked on Smartvote have been edited by a team of political scientists. They are intended to cover a broad range of political issues relevant at the time of the election:\n",
        "   * Welfare, Healthcare, Education, Immigration, Society, Security, Finances, Economy, Foreign Policy, Infrastructure & Environment, Political System, Digitisation\n",
        "\n",
        "Let us start to investigate the topics of the questions in English.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-gf3vvycTlg"
      },
      "source": [
        "##Import data\n",
        "\n",
        "Let us import the questions in English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZEPr_QFJdBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "02184aec-94a9-4b3d-abdd-28182b54f35c"
      },
      "source": [
        "import pandas as pd    \n",
        "\n",
        "!wget https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/data/questions.en.jsonl\n",
        "result = pd.read_json(path_or_buf='/content/questions.en.jsonl', lines=True)\n",
        "result.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 16:01:16--  https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/data/questions.en.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33999 (33K) [text/plain]\n",
            "Saving to: â€˜questions.en.jsonlâ€™\n",
            "\n",
            "questions.en.jsonl  100%[===================>]  33.20K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-11-22 16:01:16 (15.9 MB/s) - â€˜questions.en.jsonlâ€™ saved [33999/33999]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Do you think it is fundamentally right that th...</td>\n",
              "      <td>Welfare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Should a 24-week period of \"parental leave\" be...</td>\n",
              "      <td>Welfare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>The disability insurance system no longer prov...</td>\n",
              "      <td>Welfare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>Would you support a national hospital planning...</td>\n",
              "      <td>Healthcare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>Do you think it's right that certain forms of ...</td>\n",
              "      <td>Healthcare</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text       topic\n",
              "0   2  Do you think it is fundamentally right that th...     Welfare\n",
              "1   4  Should a 24-week period of \"parental leave\" be...     Welfare\n",
              "2   6  The disability insurance system no longer prov...     Welfare\n",
              "3   7  Would you support a national hospital planning...  Healthcare\n",
              "4   9  Do you think it's right that certain forms of ...  Healthcare"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFKN-LP1CyM4"
      },
      "source": [
        "result['topic'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg_l_Y0r4YZf"
      },
      "source": [
        "Let's drop the duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew5dv6eV3w1a"
      },
      "source": [
        "result = result.drop_duplicates(subset=['text'])\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0c_ftxjxY_H"
      },
      "source": [
        "## Importing what we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZmTpQUov8y8"
      },
      "source": [
        "from contextualized_topic_models.models.ctm import ZeroShotTM, CombinedTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
        "import nltk\n",
        "import torch\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RofQgNLZ2AL0"
      },
      "source": [
        "We are going to create a function that fixes the random seeds so that we can replicate the results. We will use this function later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkXxLLKf2B8k"
      },
      "source": [
        "def fix_seeds():\n",
        "  torch.manual_seed(10)\n",
        "  torch.cuda.manual_seed(10)\n",
        "  np.random.seed(10)\n",
        "  random.seed(10)\n",
        "  torch.backends.cudnn.enabled = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQkeIrdWLU2m"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-AM070Ez6lW"
      },
      "source": [
        "Why do we use the **preprocessed text** here? We need text without punctuation to build the bag of word. We also remove stop-words, which usually do not convey thematic information. \n",
        "Also, in some cases, we might want only to have the most frequent words inside the BoW. Too many words might not help.\n",
        "\n",
        "However, **there is not a standard pre-processing** for each dataset. In this specific case, we have only 173 documents with at most 500 words, so we don't remove less frequent words.   \n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/combined_ctm.PNG)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKrSIkxaNBt"
      },
      "source": [
        "from nltk.corpus import stopwords as stop_words\n",
        "nltk.download('stopwords')\n",
        "stopwords = list(set(stop_words.words('english')))\n",
        "\n",
        "documents = result.text.tolist()\n",
        "sp = WhiteSpacePreprocessingStopwords(documents, stopwords_list=stopwords)\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzjKh_H80UvE"
      },
      "source": [
        "Other parameters of the object `WhiteSpacePreprocessingStopwords`: \n",
        "*  *vocabulary_size*: the number of most frequent words to include in the documents. Infrequent words will be discarded from the list of preprocessed documents\n",
        "* *max_df* : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. Default: 1\n",
        "* *min_words*: Documents with less words than the parameter will be removed. Default: 1 \n",
        "* *remove_numbers*: If true, numbers are removed from the documents. Default=True. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aevSxSBbYZG"
      },
      "source": [
        "Let's check the first ten words of the vocabulary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evwSKgdyyhWq"
      },
      "source": [
        "vocab[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDxo_ERVonRE"
      },
      "source": [
        "preprocessed_documents[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVzsV8enSm6B"
      },
      "source": [
        "unpreprocessed_corpus[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stAb2Q4eBB3W"
      },
      "source": [
        "We don't discard the non-preprocessed texts, because we are going to use them as input for obtaining the contextualized document representations. \n",
        "\n",
        "Let's pass our files with preprocess and unpreprocessed data to our `TopicModelDataPreparation` object. This object takes care of creating the bag of words for you and of obtaining the contextualized representations of documents. This operation allows us to create our training dataset.\n",
        "\n",
        "Note: You can use the contextualized representation that you like. In our experiments, we noticed that a \"better\" language models usually leads to more coherent results. For this reason, we are going to use \"paraphrase-distilroberta-base-v2\". For other models: https://www.sbert.net/docs/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhLt6VA3wvCB"
      },
      "source": [
        "tp = TopicModelDataPreparation(\"paraphrase-distilroberta-base-v2\")\n",
        "\n",
        "training_dataset = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2KO4tb_d6fL"
      },
      "source": [
        "### How many topics? \n",
        "There are different techniques to select the best number of topics. In this case, I **run our topic model with a different number of topics (5, 10, 15, 20) and selected the one that produces the topics with the highest coherence**. \n",
        "\n",
        "Also remember that **a topic model is a probabilistic model, and each time produces different results** if run with the same values of hyperparameters (e.g. the same number of topics). For this reason, I've run the topic model with the same number of topics for 5 times. \n",
        "\n",
        "For time constraints, we are not going to do this, but we can play with different number of topics later. There are other techniques, for example you can use a black-box optimization strategy to find the best number of topics w.r.t. an arbitrary metric. See OCTIS: https://github.com/mind-Lab/octis\n",
        "\n",
        "However, my ultimate suggestion is to manually inspect the topics (this is reasonable if we don't have many topics to investigate). See also the references at the end of this notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSxaxusuf_rg"
      },
      "source": [
        "### Code to find the best number of topics (do not run it during the tutorial)\n",
        "\n",
        "To run this, you don't have to set the random seeds, otherwise, you will always get the same results with the same number of topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUovaiWrgIBG"
      },
      "source": [
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI, InvertedRBO\n",
        "corpus = [d.split() for d in preprocessed_documents]\n",
        "\n",
        "num_topics = [5, 10, 15, 20]\n",
        "num_runs = 5\n",
        "\n",
        "best_topic_coherence = -999\n",
        "best_num_topics = 0\n",
        "for n_components in num_topics:\n",
        "  for i in range(num_runs):\n",
        "    print(\"num topics:\", n_components, \"/ num run:\", i)\n",
        "    ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, \n",
        "                     n_components=n_components, num_epochs=50)\n",
        "    ctm.fit(training_dataset) # run the model\n",
        "    coh = CoherenceNPMI(ctm.get_topic_lists(10), corpus)\n",
        "    coh_score = coh.score()\n",
        "    print(\"coherence score:\", coh_score)\n",
        "    if best_topic_coherence < coh_score:\n",
        "      best_topic_coherence = coh_score\n",
        "      best_num_topics = n_components\n",
        "    print(\"current best coherence\", best_topic_coherence, \"/ best num topics\", best_num_topics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x-esnySk7uO"
      },
      "source": [
        "## Training our Combined Contextualized Topic Model\n",
        "Let us run the topic model with 12 topics (parameter *n_components*). \n",
        "\n",
        "Recall that CTM is a neural model. So we need to define for **how many epochs** the model will run. We can also use early stopping criterion to let the model stop automatically. In this case, we should provide a validation dataset to the `fit` function (parameter `validation_dataset`).\n",
        "\n",
        "We also need to set the dimension of the BoW and the dimension of the contextualized representation. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I3ThmBf0BcK"
      },
      "source": [
        "fix_seeds() # uncomment if you don't want to fix the random seeds\n",
        "\n",
        "num_topics = 12\n",
        "ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, n_components=num_topics, num_epochs=50)\n",
        "ctm.fit(training_dataset) # run the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQtxdOocSbV4"
      },
      "source": [
        "There are other parameters that you may want to play with:\n",
        "* *lr* (float): the learning rate, i.e. the step size at each iteration while moving towards a minimum of a loss function. If it's too small, the network will require too much time to reach a minimum, if it's too high then training may not converge;\n",
        "* *batch_size* (integer): the batch size, i.e. the number of samples that will be propagated through the network. If it's too high (batch size == num of total instances), you may not be able to fit the samples in your machine's memory. If it's too small, the less accurate the estimate of the gradient will be.\n",
        "* *hidden_sizes* (tuple of integers): the number of hidden layers and neurons. Default: (100, 100) --> two layers of 100 neurons each\n",
        "* *dropout* (float): probability of dropping out the units in the latent representation layer as regularization.\n",
        "\n",
        "You can see the full list of parameters [here](https://github.com/MilaNLProc/contextualized-topic-models/blob/6c6d6a996ceae1d203ab34a08c72f8214f98ab65/contextualized_topic_models/models/ctm.py#L19)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SEBG6wj9Zdu"
      },
      "source": [
        "# Topics\n",
        "\n",
        "After training, now it is the time to look at our topics: we can use the \n",
        "\n",
        "```\n",
        "get_topic_lists\n",
        "```\n",
        "\n",
        "function to get the topics. It also accepts a parameter that allows you to select how many words you want to see for each topic.\n",
        "\n",
        "If you look at the topics, you can see if they all make sense. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxcKgjbx3V2o"
      },
      "source": [
        "ctm.get_topic_lists(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IRVVFvTL7f"
      },
      "source": [
        "However, we also want to quantify how better the contextualized models are with respect to previous work. For example, how much does CTM perform better than LDA? \n",
        "\n",
        "Let's compare the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5NIzZuBTcVO"
      },
      "source": [
        "## Latent Dirichlet Allocation (LDA) \n",
        "We are going to use gensim library to train LDA and then assess the quality of the topics using NPMI topic coherence (normalized point-wise mutual information).\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCWx9ajODAqW"
      },
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import LdaModel \n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "split_preprocessed_documents = [d.split() for d in preprocessed_documents]\n",
        "dictionary = Dictionary(split_preprocessed_documents)\n",
        "corpus = [dictionary.doc2bow(text) for text in split_preprocessed_documents]\n",
        "\n",
        "lda = LdaModel(corpus, num_topics=num_topics, iterations=500, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_VOs2avl4ut"
      },
      "source": [
        "Let's see the topics discovered by LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzllHOlrl9Ue"
      },
      "source": [
        "def get_topics_lda(topk=10):\n",
        "  topic_terms = []\n",
        "  for i in range(num_topics):\n",
        "      topic_words_list = []\n",
        "      for word_tuple in lda.get_topic_terms(i, topk):\n",
        "          topic_words_list.append(dictionary[word_tuple[0]])\n",
        "      topic_terms.append(topic_words_list)\n",
        "  return topic_terms\n",
        "\n",
        "get_topics_lda(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH9DAiD2T9-N"
      },
      "source": [
        "### Topic Coherence\n",
        "We usually use the topic coherence as main indicator of the quality of the topics. NPMI topic coherence is the most used one and it is computed on the co-occurrences of the words in the original or in an external corpus. The intuition is that if two words often co-occur together, then they are more likely to be related to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWq40_gwT-q0"
      },
      "source": [
        "cm = CoherenceModel(model=lda, dictionary=dictionary, \n",
        "                    texts=split_preprocessed_documents, coherence='c_npmi')\n",
        "lda_coherence = cm.get_coherence()  # get coherence value\n",
        "print(\"coherence score LDA:\", lda_coherence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPD0RG8oUE89"
      },
      "source": [
        "### Coherence on CTM\n",
        "CTM library already integrates gensim's computation of coherence. We just provide the list of topics and the corpus as input to the class `CoherenceNPMI` and compute the score with the `.score()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qroSVUPpDj_s"
      },
      "source": [
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI, InvertedRBO\n",
        "corpus = [d.split() for d in preprocessed_documents]\n",
        "coh = CoherenceNPMI(ctm.get_topic_lists(10), corpus)\n",
        "print(\"coherence score CTM:\", coh.score())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDPtFgxUm-A3"
      },
      "source": [
        "### Diversity of the topics \n",
        "\n",
        "We can also compute how much diverse are the topics from each other. Ideally we expect topics which represent separate concepts or ideas. In this case, we use the IRBO (inverted ranked biased overlap) measure. Topics with common words at different rankings are penalized less than topics sharing the same words at the highest ranks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om2zK9F9nWYM",
        "outputId": "7a3acd29-d677-48c5-cac1-d8824527e1c3"
      },
      "source": [
        "irbo_lda = InvertedRBO(get_topics_lda(10))\n",
        "print(\"diversity score LDA:\", irbo_lda.score())\n",
        "\n",
        "irbo_ctm = InvertedRBO(ctm.get_topic_lists(10))\n",
        "print(\"coherence score CTM:\", irbo_ctm.score())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diversity score LDA: 0.817167000141342\n",
            "coherence score CTM: 0.9960327574487013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeNJfHvzjD2R"
      },
      "source": [
        "# Topic Predictions\n",
        "\n",
        "Now we can take a document and see which topics have been assigned to it. \n",
        "\n",
        "We first consider the topic distribution of the training documents, which CTM already computed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5O1HExjI0e"
      },
      "source": [
        "topics_predictions = ctm.training_doc_topic_distributions # get all the topic predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxzcZtnUc1Fo"
      },
      "source": [
        "Then we get the index of the most likely topic of the document of our choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJf1bP5PjqOQ"
      },
      "source": [
        "import numpy as np\n",
        "train_doc_id = 0\n",
        "topic_id = np.argmax(topics_predictions[train_doc_id]) # get the topic id of the  document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpp0N7VrdAWb"
      },
      "source": [
        "And finally get the top words of the most likely topic for the considered document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMA9vUsgjwOi"
      },
      "source": [
        "ctm.get_topic_lists(10)[topic_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGa-5qn7dJBw"
      },
      "source": [
        "Let us compare it with the original document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN_dwyTBdNgK"
      },
      "source": [
        "unpreprocessed_corpus[train_doc_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6vS9W0ZoQHb"
      },
      "source": [
        "We can also compare the topic with the corresponding ground truth label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGxM78_oc52"
      },
      "source": [
        "print(\"Original label:\", result['topic'][train_doc_id])\n",
        "print(\"Most likely topic:\", ctm.get_topic_lists(10)[topic_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aARNfNiCeCn3"
      },
      "source": [
        "## Get the top K documents for a topic\n",
        "\n",
        "A different way to explore the results consists in retrieving all the K documents which are most likely assigned to a specific topic.\n",
        "\n",
        "Let us first consider a topic index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13pT5QqgePxJ"
      },
      "source": [
        "topic_id = 5\n",
        "print(ctm.get_topics()[topic_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WeKd2ivFiTZ"
      },
      "source": [
        "And then we use the `get_top_documents_per_topic_id` function to get the list of most likely documents with their corresponding probability. The probability we see here corresponds to the conditional probability of the document to be assigned to the considered topic. The parameter `k` controls how many documents we want to retrieve.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axm6bAIWFi6d"
      },
      "source": [
        "ctm.get_top_documents_per_topic_id(unpreprocessed_corpus, ctm.training_doc_topic_distributions, topic_id, k=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIDm8B_lU0dj"
      },
      "source": [
        "# Cross-lingual Topic Modeling with Zero-shot Contextualized Topic Model \n",
        "Recall that the data we have contain answers in German, French and Italian. It would be impossible for us to predict the topics of these documents without speaking German, French or Italian. \n",
        "\n",
        "Instead of concatenating the input BoW representation with the contextualized representation, we can just replace it. And instead of using a mono-lingual representation, we can use a multilingual one.\n",
        "\n",
        "In this way, the model will take as input a multilingual representation, try to learn a good topical representation of the documents that allows it to reconstruct the original BoW.\n",
        "\n",
        "![](https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/images/zeroshot_ctm.PNG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYIwa08Je7V-"
      },
      "source": [
        "##Training our Zero-Shot Contextualized Topic Model\n",
        "Also here we need both preprocessed and unpreprocessed documents. We need the preprocessed text to extract the top words of the topics, while we need the un-preprocessed text to generate the contextualized document representations.\n",
        "We are going to use the same preprocessed and unpreprocessed corpus as before. \n",
        "\n",
        "\n",
        "But this time we are going to need a **multilingual sentence encoder**. We are going to use \"paraphrase-multilingual-mpnet-base-v2\", because it is already pre-trained on the languages that we would like to explore later (French, German and Italian)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlT-vIWAfWoW"
      },
      "source": [
        "fix_seeds() #uncomment this if you don't want to fix the seeds\n",
        "\n",
        "zero_tp = TopicModelDataPreparation(\"paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "zero_training_dataset = zero_tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bLxez7Efdq1"
      },
      "source": [
        "And we are ready to train the model. Make sure you use the \"ZeroShotTM\" class and not the \"CombinedTM\" one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twEyOwjLfBKn",
        "outputId": "7feca7a5-ae70-42e2-afda-fb8c3ddefebd"
      },
      "source": [
        "zero_ctm = ZeroShotTM(bow_size=len(zero_tp.vocab), contextual_size=768, \n",
        "                      n_components=12, num_epochs=50)\n",
        "zero_ctm.fit(zero_training_dataset) # run the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [50/50]\t Seen Samples: [8650/8650]\tTrain Loss: 78.36704355581648\tTime: 0:00:00.313294: : 50it [00:16,  3.06it/s]\n",
            "Sampling: [20/20]: : 20it [00:06,  3.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pzROQhWfnSv"
      },
      "source": [
        "### Topics \n",
        "As before, let us look at the topics of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQMlzMcvfpz5"
      },
      "source": [
        "zero_ctm.get_topic_lists(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Je_kudwYqE"
      },
      "source": [
        "### Let's predict the topics of the documents in unseen languages \n",
        "\n",
        "It's time to take advantage of the power of multilingual language models. Let's predict the topics of some answers in French, German and Italian. Rembember that these answers are in languages that the model has not seen during training.\n",
        "\n",
        "\n",
        " First, we download the data as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nPrdOguP7yq"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/silviatti/Contextualized-Topic-Models-Tutorial/main/data/test.jsonl\n",
        "\n",
        "df_test = pd.read_json(path_or_buf='/content/test.jsonl', lines=True)\n",
        "df_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6daSVWMz54A"
      },
      "source": [
        "Since the text of the answer may be insufficient to understand the context, a testing document will be composed by the question and the corresponding answer. We want something like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5uCIsSvqHIR"
      },
      "source": [
        "df_test['question'][0] + \" <SEP> \" + df_test['comment'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNpu6Idvqcls"
      },
      "source": [
        "Let's concatenate question and answer for all the instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uca-kdqxw2vU"
      },
      "source": [
        "test_docs = [quest + \" \" + answ for quest, answ in zip(df_test['question'].tolist(), df_test['comment'].tolist())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X56pyC-Athr"
      },
      "source": [
        "test_docs[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EFph7SymSMZ"
      },
      "source": [
        "There's no need to preprocess the documents if you want to do zero-shot topic modeling! (The vocabulary obtained from the French and German documents wouldn't match our English vocabulary!) Let's just pass the French, German and Italian documents as they are (without preprocessing) to our `TopicModelDataPreparation` object and create the testing dataset using the function `transform`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1TWWcFjwOgk"
      },
      "source": [
        "testing_dataset = tp.transform(test_docs) # create dataset for the testset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6sWnYF8wXp8"
      },
      "source": [
        "Now we are ready to compute the topic predictions for each document. In this case, we are going to use the function `get_thetas` because the model has never seen the documents during training. The parameter `n_samples` controls the number of times we sample from the distribution the model has learned. The higher, the more accurate the results, but it will also take more time to execute \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By9S7UIVz4Zr"
      },
      "source": [
        "# n_sample how many times to sample the distribution (see the documentation)\n",
        "test_topics_predictions = zero_ctm.get_thetas(testing_dataset, n_samples=10) # get all the topic predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQmIBoLPd6wk"
      },
      "source": [
        "Let's install this machine translation library that we are going to use later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKqWTwVhd5yF"
      },
      "source": [
        "%%capture \n",
        "!pip install deep-translator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cyb36Y7hB7y"
      },
      "source": [
        "Now we can predict the topics of documents in unseen languages. Let's consider a document with an arbitrary index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M5QSOIlkhFVP",
        "outputId": "c494763f-88ed-43a9-dfc1-4641099377dc"
      },
      "source": [
        "test_document_index=10000\n",
        "test_docs[test_document_index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"La naturalisation devrait-elle Ãªtre facilitÃ©e aux Ã©trangers de la troisiÃ¨me gÃ©nÃ©ration? pourquoi attendre 3 gÃ©nÃ©rations? je l'ai obtenue Ã  l'Ã©poque le jour de mon mariage !\""
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OhXS_5y2Ndn"
      },
      "source": [
        "Let us translate the document, only to check if the model predicts correctly the topics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "CJjAEL_OiEUF",
        "outputId": "e3430f71-d0f2-4454-a49c-67cbd1336554"
      },
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "gt = GoogleTranslator(source='auto', target='en')\n",
        "translated = gt.translate(test_docs[test_document_index])\n",
        "translated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/html5lib/_trie/_base.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Mapping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Should naturalization be made easier for third generation foreigners? why wait 3 generations? I got it at the time on my wedding day!'"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWkrjBrhUbp"
      },
      "source": [
        "Let's get the index of most likely topic of the first document and then show the topic words to see if the topic's prediction is accurate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91PGwQBZhOsQ"
      },
      "source": [
        "topic_number = np.argmax(test_topics_predictions[test_document_index]) # get the topic id of the first document\n",
        "zero_ctm.get_topic_lists(15)[topic_number] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAapvH3hlDk"
      },
      "source": [
        "### Top K documents per topic\n",
        "Also in this case, we can retrieve the top K documents which are most likely assigned to a given topic. Let us use the function `get_top_documents_per_topic_id` as before, but in this case, we will use the `test_docs` and `test_topic_predictions` as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71CWic5ZWxJg"
      },
      "source": [
        "topic_id = 1\n",
        "print(zero_ctm.get_topics()[topic_id])\n",
        "top_documents = zero_ctm.get_top_documents_per_topic_id(test_docs, test_topics_predictions, topic_id, k=10)\n",
        "top_documents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyvcWF8Ls7YV"
      },
      "source": [
        "Let's translate the documents to check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjkGEsBUs6pc"
      },
      "source": [
        "for original_doc, probability in top_documents:\n",
        "  print(gt.translate(original_doc), probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr1quLzSgs37"
      },
      "source": [
        "### Topic distribution on the overall corpus  (training vs test)\n",
        "\n",
        "Given the discovered topics, we can investigate how the topics distribute in the training and the testing set. It's easier if we try to assign a label to each topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCC11MOe5NG1"
      },
      "source": [
        "Let's try to assign a label to each discovered topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMLcuYsm5TJK"
      },
      "source": [
        "labels = ['topic_0', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7', 'topic_8', 'topic_9', \n",
        "          'topic_10', 'topic_11']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig_qylHn5nEr"
      },
      "source": [
        "Maybe it's helpful to find the most likely training documents for a given topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5WX4CXW5u4d"
      },
      "source": [
        "topic_id = 4\n",
        "print(zero_ctm.get_topic_lists(10)[topic_id])\n",
        "ctm.get_top_documents_per_topic_id(unpreprocessed_corpus, zero_ctm.training_doc_topic_distributions, topic_id, k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX9ZBpGf3G8Y"
      },
      "source": [
        "print(labels,\"\\n\")\n",
        "\n",
        "zero_ctm.get_topic_lists(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOlHwrwuoScU"
      },
      "source": [
        "Now we can see how the different topics distribute over the whole training corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Yprf4P3MCx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(np.average(zero_ctm.training_doc_topic_distributions,axis=0),\n",
        "        labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')  \n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl846anIoZs_"
      },
      "source": [
        "And we can compare this with the testing corpus "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q-T2CXmLo4j"
      },
      "source": [
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(np.average(test_topics_predictions,axis=0),\n",
        "        labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')  \n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zdqc_sYzUsE"
      },
      "source": [
        "We can also compare the distribution of the topics between the different languages. Let's split the topic predictions by language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW4tyfAlzvC-"
      },
      "source": [
        "test_topics_predictions_it, test_topics_predictions_de, test_topics_predictions_fr = [], [], [] \n",
        "for ttp, lang in zip(test_topics_predictions, df_test['language'].tolist()):\n",
        "  if lang == 'it':\n",
        "    test_topics_predictions_it.append(ttp)\n",
        "  elif lang == 'de':\n",
        "    test_topics_predictions_de.append(ttp)\n",
        "  elif lang == 'fr':\n",
        "    test_topics_predictions_fr.append(ttp)\n",
        "  else:\n",
        "    print('something went wrong')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANdwPmEX0kPn"
      },
      "source": [
        "Now we are ready to plot the different distributions, as seen above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV3ZCWII0rXQ"
      },
      "source": [
        "fig1, axs = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\n",
        "axs[0].pie(np.average(test_topics_predictions_it,axis=0),\n",
        "        labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "axs[0].axis('equal')  \n",
        "axs[0].title.set_text('ITALIAN')\n",
        "\n",
        "axs[1].pie(np.average(test_topics_predictions_de,axis=0),\n",
        "        labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "axs[1].axis('equal')  \n",
        "axs[1].title.set_text('GERMAN')\n",
        "\n",
        "\n",
        "axs[2].pie(np.average(test_topics_predictions_fr,axis=0),\n",
        "        labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "axs[2].axis('equal')  \n",
        "axs[2].title.set_text('FRENCH')\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2lGoochpRs1"
      },
      "source": [
        "# What's next?\n",
        "\n",
        "## Kitty\n",
        "**Kitty** classifies documents using a human in the loop approach supported by Contextualized Topic Models.\n",
        "\n",
        "![](https://github.com/silviatti/Contextualized-Topic-Models-Tutorial/blob/main/images/kitty.PNG?raw=true)\n",
        "\n",
        "[Link](https://contextualized-topic-models.readthedocs.io/en/develop/kitty.html)\n",
        "\n",
        "## OCTIS\n",
        "\n",
        "**OCTIS (Optimizing and Comparing Topic models Is Simple)** can discover automatically the optimal hyperparameter configuration w.r.t. a given evaluation metric. It also contains CTM but many other models and different evaluation metrics.\n",
        "\n",
        "![](https://github.com/MIND-Lab/OCTIS/blob/master/logo.png?raw=true)\n",
        "\n",
        "\n",
        "[Link](https://github.com/MIND-Lab/OCTIS/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7A8M0xiUIJS"
      },
      "source": [
        "## Additional Resources \n",
        "* Jordan Boyd-Graber, David Mimno, and David Newman. \"Care and Feeding of Topic Models: Problems,\n",
        "Diagnostics, and Improvements\": https://home.cs.colorado.edu/~jbg/docs/2014_book_chapter_care_and_feeding.pdf\n",
        "*  David Mimno, Jordan Boyd-Graber, and Yuening Hu. \"Applications of Topic Models\": https://mimno.infosci.cornell.edu/papers/2017_fntir_tm_applications.pdf"
      ]
    }
  ]
}